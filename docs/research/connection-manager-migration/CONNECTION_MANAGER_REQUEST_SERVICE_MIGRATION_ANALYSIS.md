# ConnectionManagerRequestService Migration Analysis

**Status**: Research Complete - Implementation NOT Recommended
**Date**: 2025-01-08
**Last Updated**: 2025-01-08 (Deep-dive investigation completed)
**Risk Level**: HIGH - Large refactor with discovered critical incompatibilities
**Complexity**: HIGHER THAN INITIALLY ASSESSED

---

## ‚ö†Ô∏è CRITICAL FINDINGS SUMMARY

Deep investigation revealed **SIGNIFICANT ARCHITECTURAL INCOMPATIBILITIES** that were not apparent in initial analysis:

1. **EVENT SYSTEM BYPASS** - ConnectionManagerRequestService does NOT emit `CHAT_COMPLETION_PROMPT_READY` event
2. **OPERATION TYPE DETECTION BREAKS** - Stack trace analysis incompatible with new call path
3. **DUAL INJECTION PATH COMPLEXITY** - Must maintain two separate metadata injection systems
4. **OPERATIONCONTEXT PATTERN INCOMPATIBLE** - Global state pattern must be completely refactored

**For detailed end-to-end traces of each issue, see [TECHNICAL_ISSUE_TRACES.md](TECHNICAL_ISSUE_TRACES.md)** - 1,638 lines with complete code flows, call stacks, timing diagrams, and before/after comparisons.

**Revised Effort Estimate**: **~~120 hours~~** ‚Üí **50-65 hours** (see scope corrections below)

**Recommendation**: **DO NOT PROCEED** without 15-20 hour pilot phase to validate approach

---

## üî¥ SCOPE CORRECTIONS (2025-01-08 Verification)

**CRITICAL**: Comprehensive verification revealed original analysis **significantly overestimated** refactor scope:

| Aspect | Originally Claimed | Actually Verified | Variance |
|--------|-------------------|------------------|----------|
| **Files to update** | 30+ files | **8-10 files** | -67% to -73% |
| **Call sites** | 50-100+ sites | **15-20 sites** | -70% to -80% |
| **Existing tests** | 100+ tests | **0 tests** | -100% (NO TESTS EXIST) |
| **Development effort** | 80 hours | **40-50 hours** | -38% to -50% |
| **Testing effort** | 40 hours | **10-15 hours** | -63% to -75% |
| **Total effort** | 120 hours | **50-65 hours** | -46% to -58% |
| **Pilot phase** | 40 hours | **15-20 hours** | -50% to -63% |

**‚úÖ Core technical claims remain VERIFIED** (event system, stack trace, architecture)

**‚ö†Ô∏è Additional analysis needed**:
- Event listeners: Only 1 of 14+ analyzed
- Error handling: Not analyzed
- Streaming behavior: Not analyzed

**See VERIFICATION_REPORT.md for complete audit evidence.**

---

## Table of Contents

1. [Scope Corrections](#-scope-corrections-2025-01-08-verification) **‚Üê READ THIS FIRST**
2. [Executive Summary](#executive-summary)
3. [Current vs. Proposed Approach](#current-vs-proposed-approach)
4. [CRITICAL: Event System Incompatibility](#critical-event-system-incompatibility)
5. [CRITICAL: Operation Type Detection Incompatibility](#critical-operation-type-detection-incompatibility)
6. [SillyTavern ConnectionManagerRequestService Verification](#sillytavern-connectionmanagerrequestservice-verification)
7. [Current Implementation Deep Analysis](#current-implementation-deep-analysis)
8. [Required Changes (Updated with Critical Findings)](#required-changes-updated-with-critical-findings)
9. [Testing Strategy (Updated)](#testing-strategy-updated)
10. [Risk Assessment (Updated)](#risk-assessment-updated)
11. [Benefits vs. Costs (Updated)](#benefits-vs-costs-updated)
12. [Decision Criteria](#decision-criteria)
13. [Recommendations](#recommendations)
14. [Appendices](#appendices)

**See also:** [TECHNICAL_ISSUE_TRACES.md](TECHNICAL_ISSUE_TRACES.md) for complete end-to-end traces of each technical issue with call stacks, timing diagrams, and code flows.

---

## Executive Summary

This document analyzes migrating from our current approach (slash command profile switching + `generateRaw()`) to SillyTavern's `ConnectionManagerRequestService` API for connection profile management.

### Current Approach
```javascript
await set_connection_profile(profileName);  // Changes global state
await new Promise(resolve => setTimeout(resolve, 500));  // Wait for profile to apply
const result = await generateRaw({ prompt });  // Uses active profile
```

### Proposed Approach
```javascript
// Metadata must be injected BEFORE calling (not during via interceptor)
const promptWithMetadata = injectMetadata(prompt, { operation: 'summary' });

const result = await ConnectionManagerRequestService.sendRequest(
    profileId,              // Profile used for this request only
    promptWithMetadata,     // Prompt with metadata already injected
    maxTokens,
    { /* options */ }
);
// No global state change, no delay, NO EVENTS EMITTED
```

### Key Benefits
1. **No 500ms delay** per operation
2. **No global state changes** - user's active profile unaffected
3. **Concurrent operations possible** with different profiles
4. **User can chat while operations run** in background

### Key Risks (UPDATED)
1. **Event system bypass** - CHAT_COMPLETION_PROMPT_READY not emitted (CRITICAL)
2. **Operation type detection breaks** - Stack trace analysis incompatible (CRITICAL)
3. **Dual injection paths required** - Must maintain both event and manual injection (MEDIUM)
4. **100+ test files** assume current flow (HIGH)
5. **Large refactor** touching 30+ files, 100+ call sites (HIGH)
6. **operationContext pattern incompatible** - Must refactor 15+ call sites (MEDIUM)

---

## Current vs. Proposed Approach

### Architecture Comparison

#### Current Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ USER CHAT MESSAGE                                            ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  User types message                                          ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ST's Generate() function                                    ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  generateRaw() (script.js:3190)                              ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  sendOpenAIRequest() (openai.js:2272)                        ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Line 1533: eventSource.emit(CHAT_COMPLETION_PROMPT_READY)  ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  OUR EVENT HANDLER RUNS (eventHandlers.js:297)              ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Metadata injected into chat array                           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Backend request sent                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EXTENSION OPERATION (Current)                                ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  Operation handler                                           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  set_connection_profile(name) - 500ms delay                 ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  generateRaw({ prompt })                                     ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  INTERCEPTOR WRAPS (generateRawInterceptor.js:15)           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  determineOperationType() - stack trace analysis             ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Metadata injected                                           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  SillyTavern's generateRaw()                                ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  sendOpenAIRequest()                                         ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Line 1533: Event emitted (but handler skips - lines 325-330)‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Backend request sent                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Proposed Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ USER CHAT MESSAGE (UNCHANGED)                                ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  User types message                                          ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ST's Generate() function                                    ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  generateRaw()                                               ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  sendOpenAIRequest()                                         ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Line 1533: Event emitted                                   ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  OUR EVENT HANDLER RUNS                                      ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Metadata injected                                           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Backend request sent                                        ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  NO CHANGES TO USER CHAT FLOW                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EXTENSION OPERATION (Proposed)                               ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  Operation handler                                           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  sendLLMRequest({                                            ‚îÇ
‚îÇ    prompt,                                                   ‚îÇ
‚îÇ    operationType: 'detect_scene_break',  ‚Üê MUST BE EXPLICIT ‚îÇ
‚îÇ    profileName                                               ‚îÇ
‚îÇ  })                                                          ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  llmClient.js                                                ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Inject metadata BEFORE calling API                          ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ConnectionManagerRequestService.sendRequest()               ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ChatCompletionService.processRequest()                      ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ChatCompletionService.sendRequest()                         ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  fetch('/api/backends/chat-completions/generate')           ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  ‚ùå NO EVENT EMITTED ‚ùå                                      ‚îÇ
‚îÇ   ‚Üì                                                           ‚îÇ
‚îÇ  Backend request sent                                        ‚îÇ
‚îÇ                                                               ‚îÇ
‚îÇ  CRITICAL: Event system bypassed completely                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## CRITICAL: Event System Incompatibility

> **üìñ For complete end-to-end trace with call stacks and code flows, see [TECHNICAL_ISSUE_TRACES.md ¬ß1](TECHNICAL_ISSUE_TRACES.md#1-event-system-bypass)**

### Discovery

During deep-dive investigation, discovered that **ConnectionManagerRequestService DOES NOT emit the `CHAT_COMPLETION_PROMPT_READY` event** that our extension relies on for metadata injection.

### Evidence

**VERIFIED**: Event only emitted in ONE place in entire SillyTavern codebase:

**openai.js:1533** (inside `sendOpenAIRequest()` function):
```javascript
const eventData = { chat, dryRun };
await eventSource.emit(event_types.CHAT_COMPLETION_PROMPT_READY, eventData);
```

**VERIFIED**: ConnectionManagerRequestService bypasses this:

**custom-request.js** verified via grep - ZERO event emissions:
```bash
$ grep -n "emit.*CHAT_COMPLETION_PROMPT_READY" custom-request.js
# NO RESULTS

$ grep -n "eventSource" custom-request.js
# NO RESULTS
```

**Call path verification**:
```
ConnectionManagerRequestService.sendRequest() (shared.js:383)
  ‚Üì
ChatCompletionService.processRequest() (custom-request.js:535)
  ‚Üì
ChatCompletionService.sendRequest() (custom-request.js:453)
  ‚Üì
fetch('/api/backends/chat-completions/generate')  ‚Üê DIRECT TO BACKEND
  ‚Üì
‚ùå NO EVENT EMITTED ANYWHERE IN THIS PATH ‚ùå
```

### Impact on Our Extension

We currently use this event for **user chat message** metadata injection:

**eventHandlers.js:297-364**:
```javascript
eventSource.on(event_types.CHAT_COMPLETION_PROMPT_READY, async (promptData) => {
  await on_chat_event('chat_completion_prompt_ready', promptData);

  try {
    // Check if injection is enabled
    const enabled = get_settings('first_hop_proxy_send_chat_details');
    if (!enabled) {return;}

    // Process the chat array
    if (promptData && Array.isArray(promptData.chat)) {
      // Check if an extension operation is already in progress
      const { getOperationSuffix } = await import('./operationContext.js');
      const operationSuffix = getOperationSuffix();

      if (operationSuffix !== null) {
        // Extension operation in progress (summary, scene, etc.)
        // The generateRawInterceptor will handle metadata injection
        debug('[Interceptor] Extension operation in progress, skipping chat-{index} metadata');
        return;  // ‚Üê SKIP event-based injection for extension operations
      }

      // Only inject chat-{index} for actual user/character messages
      const context = getContext();
      const messageIndex = (context?.chat?.length ?? 0) - 1;

      // Build operation string: chat-{index} or chat-{index}-swipe{n}
      let operation = `chat-${messageIndex}`;
      if (lastMessage?.swipe_id > 0) {
        operation += `-swipe${swipeId + 1}`;
      }

      injectMetadataIntoChatArray(promptData.chat, { operation });
      debug(`[Interceptor] Injected metadata with operation: ${operation}`);
    }
  } catch (err) {
    debug('[Interceptor] Error processing CHAT_COMPLETION_PROMPT_READY:', String(err));
  }
});
```

### Impact Assessment

| Scenario | Current Behavior | With ConnectionManagerRequestService |
|----------|------------------|-------------------------------------|
| **User sends chat message** | ‚úÖ generateRaw() called<br>‚úÖ Event fires<br>‚úÖ Handler runs<br>‚úÖ Metadata injected | ‚úÖ SAME - Uses ST's normal flow<br>‚úÖ Event fires<br>‚úÖ Handler runs<br>‚úÖ NO IMPACT |
| **Extension operation (current)** | ‚úÖ generateRaw() called<br>‚úÖ Interceptor injects metadata<br>‚úÖ Event fires but handler skips (line 325-330)<br>‚úÖ Metadata already injected | N/A - Current system |
| **Extension operation (proposed)** | N/A | ‚ùå ConnectionManagerRequestService called<br>‚ùå Event does NOT fire<br>‚ùå Handler does NOT run<br>‚úÖ BUT metadata injected manually before calling<br>‚úÖ MITIGATION WORKS |

### Mitigation Strategy

**Extension operations**: Inject metadata **manually BEFORE** calling ConnectionManagerRequestService
**User chat messages**: Continue using ST's normal flow (generateRaw ‚Üí sendOpenAIRequest) - **NO CHANGES**

**Result**: Dual injection path system required:
1. **Event-based injection** for user chat messages (existing code, unchanged)
2. **Manual injection** for extension operations (new code, in llmClient.js)

---

## CRITICAL: Operation Type Detection Incompatibility

> **üìñ For complete end-to-end trace with call stacks and examples, see [TECHNICAL_ISSUE_TRACES.md ¬ß2](TECHNICAL_ISSUE_TRACES.md#2-stack-trace-analysis-incompatibility)**

### Current System: Stack Trace Analysis

**generateRawInterceptor.js:121-179**:
```javascript
function determineOperationType() {
  try {
    // Try to determine from call stack
    const stack = new Error('Stack trace for operation type detection').stack || '';

    // Check for specific scene operations FIRST (before generic summarize_text check)
    if (stack.includes('detectSceneBreak') || stack.includes('autoSceneBreakDetection.js')) {
      return 'detect_scene_break';
    }
    if (stack.includes('generateSceneSummary') && !stack.includes('runningSceneSummary.js')) {
      return 'generate_scene_summary';
    }
    if (stack.includes('SceneName') || stack.includes('sceneNamePrompt')) {
      return 'generate_scene_name';
    }
    if (stack.includes('generate_running_scene_summary') || stack.includes('runningSceneSummary.js')) {
      return 'generate_running_summary';
    }

    // Check for validation operations
    if (stack.includes('validateSummary') || stack.includes('summaryValidation.js')) {
      return 'validate_summary';
    }

    // Check for specific lorebook operations
    if (stack.includes('runLorebookEntryLookupStage')) {
      return 'lorebook_entry_lookup';
    }
    if (stack.includes('runLorebookEntryDeduplicateStage')) {
      return 'resolve_lorebook_entry';
    }
    // ... more operation types ...

    // Check for message summarization (AFTER scene checks!)
    if (stack.includes('summarize_text') || stack.includes('summarization.js')) {
      return 'summary';
    }

    // Default for chat messages
    return 'chat';
  } catch {
    return 'unknown';
  }
}
```

**Why this works**: `generateRaw()` is called from within our extension functions, so their names appear in the call stack:

```
Stack trace example when summarizing:
  at generateRaw (script.js:3190)
  at wrappedGenerateRaw (generateRawInterceptor.js:15)
  at summarize_text (summarization.js:15)        ‚Üê DETECTED
  at handle_summarize_text (operationHandlers.js:...)
  ...
```

### With ConnectionManagerRequestService: Stack Trace Breaks

**Proposed call stack**:
```
  at fetch (native)
  at ChatCompletionService.sendRequest (custom-request.js:453)
  at ChatCompletionService.processRequest (custom-request.js:535)
  at ConnectionManagerRequestService.sendRequest (shared.js:383)
  at sendLLMRequest (llmClient.js:...)          ‚Üê ONLY THIS VISIBLE
  at summarize_text (summarization.js:15)       ‚Üê NOT CALLED YET!
  ...
```

**Problem**: By the time metadata needs to be injected (in `sendLLMRequest()`), the original caller functions are **NOT YET in the stack** because:
1. `summarize_text()` calls `sendLLMRequest()`
2. `sendLLMRequest()` needs to inject metadata NOW
3. Stack only shows `sendLLMRequest ‚Üí ConnectionManagerRequestService ‚Üí ...`
4. Original function names like `detectSceneBreak`, `validateSummary`, etc. are **NOT in stack yet**

**Verified**: Stack trace only includes functions that have **already been called**, not functions that **are calling you**.

### Solution: Explicit Operation Type Parameter

**MUST pass operation type explicitly at every call site**:

```javascript
// ‚ùå OLD (implicit from stack trace):
async function summarize_text(prompt) {
  // ...
  await generateRaw({ prompt });
  // Interceptor determines type from stack: 'summary'
}

// ‚úÖ NEW (explicit parameter):
async function summarize_text(prompt) {
  // ...
  await sendLLMRequest({
    prompt,
    operationType: 'summary',  // ‚Üê MUST SPECIFY EXPLICITLY
    profileName,
  });
}
```

### Impact

**EVERY LLM call site** must be updated to pass operation type explicitly.

**Estimated call sites**:
- summarization.js: 3 call sites
- lorebookEntryMerger.js: 3 call sites
- autoSceneBreakDetection.js: 1 call site
- runningSceneSummary.js: 2 call sites
- sceneBreak.js: 2 call sites
- summaryValidation.js: 1 call site
- summaryToLorebookProcessor.js: 5+ call sites
- **TOTAL: 30+ files, 50+ call sites minimum**

**Verification required**: Grep every file to ensure all call sites updated

### Alternative Considered: Pre-set Operation Type

```javascript
// Set before calling
setOperationType('detect_scene_break');
await sendLLMRequest({ prompt });
// Clear after
clearOperationType();
```

**Rejected**: Same global state problem as operationContext, doesn't solve the issue

### Recommended Approach: Operation Type Enum

**Create constants file**:
```javascript
// operationTypes.js
export const OperationType = {
  SUMMARY: 'summary',
  DETECT_SCENE_BREAK: 'detect_scene_break',
  GENERATE_SCENE_SUMMARY: 'generate_scene_summary',
  GENERATE_SCENE_NAME: 'generate_scene_name',
  VALIDATE_SUMMARY: 'validate_summary',
  LOREBOOK_ENTRY_LOOKUP: 'lorebook_entry_lookup',
  MERGE_LOREBOOK_ENTRY: 'merge_lorebook_entry',
  // ... all operation types ...
};
```

**Usage**:
```javascript
import { OperationType } from './operationTypes.js';

await sendLLMRequest({
  prompt,
  operationType: OperationType.SUMMARY,  // Type-safe, discoverable
  profileName,
});
```

---

## CRITICAL: Dual Injection Path Complexity

> **üìñ For complete end-to-end trace of all injection paths, see [TECHNICAL_ISSUE_TRACES.md ¬ß3](TECHNICAL_ISSUE_TRACES.md#3-dual-injection-path-complexity)**

### Current System: Two Injection Paths

We currently maintain **TWO SEPARATE METADATA INJECTION PATHS**:

#### Path 1: Interceptor (for extension operations)

**File**: generateRawInterceptor.js:15-74

**Activated**: When extension calls `generateRaw()`

**Operation type**: Determined from **stack trace analysis**

**Injection point**: DURING generateRaw call (inside interceptor wrapper)

```javascript
export async function wrappedGenerateRaw(options) {
  if (_isInterceptorActive) {
    return await _importedGenerateRaw(options);
  }

  try {
    _isInterceptorActive = true;

    if (options && options.prompt) {
      // Determine operation type from call stack
      const baseOperation = determineOperationType();  // Stack trace
      const suffix = getOperationSuffix();  // From global state
      const operation = suffix ? `${baseOperation}${suffix}` : baseOperation;

      if (typeof options.prompt === 'string') {
        const processedPrompt = injectMetadata(options.prompt, { operation });
        options.prompt = processedPrompt;
      } else if (Array.isArray(options.prompt)) {
        injectMetadataIntoChatArray(options.prompt, { operation });
      }
    }

    return await _importedGenerateRaw(options);
  } finally {
    _isInterceptorActive = false;
  }
}
```

#### Path 2: Event Handler (for user chat messages)

**File**: eventHandlers.js:297-364

**Activated**: When `CHAT_COMPLETION_PROMPT_READY` event fires

**Operation type**: Calculated as `chat-{index}` or `chat-{index}-swipe{n}`

**Injection point**: AFTER prompt assembled, BEFORE backend call

```javascript
eventSource.on(event_types.CHAT_COMPLETION_PROMPT_READY, async (promptData) => {
  const enabled = get_settings('first_hop_proxy_send_chat_details');
  if (!enabled) {return;}

  if (promptData && Array.isArray(promptData.chat)) {
    // Skip if extension operation in progress
    const operationSuffix = getOperationSuffix();
    if (operationSuffix !== null) {
      return;  // Interceptor handled it
    }

    // User chat message
    const messageIndex = (context?.chat?.length ?? 0) - 1;
    let operation = `chat-${messageIndex}`;

    injectMetadataIntoChatArray(promptData.chat, { operation });
  }
});
```

### Why Two Paths Exist

**Interceptor path**:
- Extension operations need operation-specific types (summary, scene, lorebook, etc.)
- Stack trace provides this information implicitly
- Activated when extension calls generateRaw()

**Event path**:
- User chat messages need message-specific identification
- Message index provides this information
- Activated when ST's normal chat flow emits event

**Both paths** ultimately call `injectMetadataIntoChatArray()` from metadataInjector.js

### With ConnectionManagerRequestService: Three Paths Required

**Path 1: Manual Injection (for extension operations - NEW)**
```javascript
// llmClient.js
export async function sendLLMRequest(options) {
  // Inject metadata BEFORE calling API
  const promptWithMetadata = injectMetadata(prompt, {
    operation: options.operationType  // EXPLICIT, not from stack
  });

  return await ConnectionManagerRequestService.sendRequest(...);
}
```

**Path 2: Event Handler (for user chat messages - UNCHANGED)**
```javascript
eventSource.on(event_types.CHAT_COMPLETION_PROMPT_READY, async (promptData) => {
  // Same as current - handles user chat messages
  injectMetadataIntoChatArray(promptData.chat, { operation: `chat-${messageIndex}` });
});
```

**Path 3: Interceptor (LEGACY - kept for fallback)**
```javascript
// Keep for:
// - ConnectionManager disabled
// - Emergency fallback
// - Other extensions that might call our code
```

### Maintenance Burden

**Current**: 2 paths, both automatic
- Interceptor: Automatic operation detection via stack
- Event handler: Automatic index detection

**Proposed**: 3 paths, one manual
- Manual: Explicit operation type at every call site (30+ files)
- Event handler: Automatic (unchanged)
- Interceptor: Kept but unused (dead code if fully migrated)

---

## CRITICAL: operationContext Pattern Incompatibility

> **üìñ For complete end-to-end trace with timing diagrams, see [TECHNICAL_ISSUE_TRACES.md ¬ß4](TECHNICAL_ISSUE_TRACES.md#4-operationcontext-pattern-incompatibility)**

### Current Pattern: Global State for Context

**File**: operationContext.js

```javascript
let currentSuffix = null;

export function setOperationSuffix(suffix) {
  currentSuffix = suffix;
}

export function getOperationSuffix() {
  return currentSuffix;
}

export function clearOperationSuffix() {
  currentSuffix = null;
}
```

**Purpose**: Add context to operation type (e.g., message range for summaries)

**Usage pattern**:
```javascript
// In operation handler
setOperationSuffix('-42-67');  // Message range
try {
  await generateRaw({ prompt });
  // Interceptor reads suffix via getOperationSuffix()
  // Operation becomes: "summary-42-67"
} finally {
  clearOperationSuffix();  // Always cleanup
}
```

**Why this works**:
- Global state set BEFORE calling generateRaw()
- Interceptor reads global state DURING call
- Cleanup in finally block ensures no leaks

### With ConnectionManagerRequestService: Pattern Breaks

**Problem**: Can't read global state at injection time because injection happens BEFORE call

**Current flow**:
```
1. setOperationSuffix('-42-67')
2. Call generateRaw()
3. Interceptor runs, reads getOperationSuffix() ‚Üí '-42-67'
4. Builds operation: baseOperation + suffix
5. Injects metadata with full operation string
6. clearOperationSuffix()
```

**Proposed flow**:
```
1. setOperationSuffix('-42-67')  // When to call this?
2. Call sendLLMRequest()
3. MUST inject metadata NOW
4. But operation type parameter is static (passed at call time)
5. Can't combine with suffix set earlier
```

**Timing issue**: Suffix needs to be combined with operation type at the same time, but:
- Operation type: Passed as parameter to `sendLLMRequest()`
- Suffix: Set via global state before calling

Can't merge them without:
- Reading global state in `sendLLMRequest()` (couples to global state)
- OR passing suffix as parameter (changes call signature)

### Solution: Build Full Operation String Before Calling

**Remove global state pattern entirely**:

```javascript
// ‚ùå OLD (global state):
setOperationSuffix('-42-67');
try {
  await generateRaw({ prompt });
} finally {
  clearOperationSuffix();
}

// ‚úÖ NEW (explicit string):
const operation = `summary-42-67`;  // Build full string upfront
await sendLLMRequest({
  prompt,
  operationType: operation,  // Pass complete operation string
  profileName,
});
// No cleanup needed
```

### Impact

**Files using operationContext**:

```bash
$ grep -r "setOperationSuffix\|getOperationSuffix\|clearOperationSuffix" *.js
```

**Estimated**: 15+ call sites across:
- operationHandlers.js: 8+ sites
- summaryToLorebookProcessor.js: 3+ sites
- runningSceneSummary.js: 2 sites
- sceneBreak.js: 2 sites

**Changes required**:
1. Remove all `setOperationSuffix()` calls
2. Remove all `clearOperationSuffix()` calls
3. Build operation string directly
4. Pass to `sendLLMRequest()`

**After migration**: operationContext.js can be deleted entirely

---

## SillyTavern ConnectionManagerRequestService Verification

All findings verified against actual SillyTavern source code (not assumed or guessed).

### Implementation Location

**File**: `/public/scripts/extensions/shared.js:352-445`

**Class**: `ConnectionManagerRequestService`

**Availability**: Exported via `getContext().ConnectionManagerRequestService`

**Verified**: Import available in st-context.js:232

### Method Signature (Verified)

```javascript
/**
 * @param {string} profileId - Connection profile ID
 * @param {string | ChatCompletionMessage[]} prompt - Prompt (string or messages array)
 * @param {number} maxTokens - Maximum tokens to generate
 * @param {Object} custom - Optional parameters
 * @param {boolean?} [custom.stream=false] - Whether to stream
 * @param {AbortSignal?} [custom.signal] - Abort signal
 * @param {boolean?} [custom.extractData=true] - Extract message from response
 * @param {boolean?} [custom.includePreset=true] - Apply preset settings
 * @param {boolean?} [custom.includeInstruct=true] - Apply instruct formatting
 * @param {Partial<InstructSettings>?} [custom.instructSettings] - Override instruct settings
 * @param {Record<string, any>} [overridePayload] - Override payload for request
 * @returns {Promise<ExtractedData | AsyncGenerator>} Response
 */
static async sendRequest(profileId, prompt, maxTokens, custom, overridePayload)
```

### Execution Flow (Line-by-Line Verified)

#### Step 1: Profile Lookup (Read-Only) - Line 391

```javascript
const profile = context.extensionSettings.connectionManager.profiles.find((p) => p.id === profileId);
```

**Verified**:
- Uses `Array.find()` - read-only operation
- Reads from `extension_settings.connectionManager.profiles` array
- **NO MODIFICATION** of global state

#### Step 2: Profile Validation (Read-Only) - Line 392

```javascript
const selectedApiMap = this.validateProfile(profile);
```

**validateProfile() implementation** (lines 491-509):
```javascript
static validateProfile(profile) {
  if (!profile) {
    throw new Error('Could not find profile.');
  }
  if (!profile.api) {
    throw new Error('Select a connection profile that has an API');
  }

  const context = SillyTavern.getContext();
  const selectedApiMap = context.CONNECT_API_MAP[profile.api];  // ‚Üê READ from map
  if (!selectedApiMap) {
    throw new Error(`Unknown API type ${profile.api}`);
  }
  if (!Object.hasOwn(this.getAllowedTypes(), selectedApiMap.selected)) {
    throw new Error(`API type ${selectedApiMap.selected} is not supported.`);
  }

  return selectedApiMap;  // Returns mapping, NO STATE CHANGE
}
```

**Verified**: No global state modifications

#### Step 3: API-Specific Processing

**For OpenAI/Chat Completion** (lines 396-418):
```javascript
case 'openai': {
  if (!selectedApiMap.source) {
    throw new Error(`API type ${selectedApiMap.selected} does not support chat completions`);
  }

  const proxyPreset = proxies.find((p) => p.name === profile.proxy);  // ‚Üê READ ONLY

  const messages = Array.isArray(prompt) ? prompt : [{ role: 'user', content: prompt }];

  return await context.ChatCompletionService.processRequest({
    stream,
    messages,
    max_tokens: maxTokens,
    model: profile.model,                           // ‚Üê FROM PROFILE
    chat_completion_source: selectedApiMap.source,  // ‚Üê FROM PROFILE
    custom_url: profile['api-url'],                 // ‚Üê FROM PROFILE
    reverse_proxy: proxyPreset?.url,                // ‚Üê FROM PROFILE
    proxy_password: proxyPreset?.password,          // ‚Üê FROM PROFILE
    custom_prompt_post_processing: profile['prompt-post-processing'], // ‚Üê FROM PROFILE
    ...overridePayload,
  }, {
    presetName: includePreset ? profile.preset : undefined,  // ‚Üê FROM PROFILE
  }, extractData, signal);
}
```

**Verified**:
- All data from profile passed as **function parameters**
- No global variables modified
- `proxies.find()` is read-only

**For Text Completion** (lines 419-437):
```javascript
case 'textgenerationwebui': {
  if (!selectedApiMap.type) {
    throw new Error(`API type ${selectedApiMap.selected} does not support text completions`);
  }

  return await context.TextCompletionService.processRequest({
    stream,
    prompt,
    max_tokens: maxTokens,
    model: profile.model,              // ‚Üê FROM PROFILE
    api_type: selectedApiMap.type,     // ‚Üê FROM PROFILE
    api_server: profile['api-url'],    // ‚Üê FROM PROFILE
    ...overridePayload,
  }, {
    instructName: includeInstruct ? profile.instruct : undefined,  // ‚Üê FROM PROFILE
    presetName: includePreset ? profile.preset : undefined,        // ‚Üê FROM PROFILE
    instructSettings: includeInstruct ? instructSettings : undefined,
  }, extractData, signal);
}
```

**Verified**: Same pattern - all data from profile passed as parameters

### Preset Handling (Verified Line-by-Line)

#### ChatCompletionService.processRequest (custom-request.js:535-558)

```javascript
static async processRequest(custom, options, extractData = true, signal = null) {
  const { presetName } = options;
  let requestData = { ...custom };  // ‚Üê LOCAL VARIABLE

  // Apply generation preset if specified
  if (presetName) {
    const presetManager = getPresetManager(this.TYPE);  // ‚Üê GET MANAGER
    if (presetManager) {
      const preset = presetManager.getCompletionPresetByName(presetName);  // ‚Üê READ ONLY
      if (preset) {
        // Convert preset to payload and merge with custom parameters
        const presetPayload = this.presetToGeneratePayload(preset, {});
        requestData = { ...presetPayload, ...requestData };  // ‚Üê MERGE INTO LOCAL VAR
      } else {
        console.warn(`Preset "${presetName}" not found, continuing with default settings`);
      }
    } else {
      console.warn('Preset manager not found, continuing with default settings');
    }
  }

  const data = this.createRequestData(requestData);  // ‚Üê CREATE REQUEST
  return await this.sendRequest(data, extractData, signal);  // ‚Üê SEND TO BACKEND
}
```

**Verified**:
- `requestData` is **local variable** (line 537)
- Preset merged into local variable (line 547)
- **NO GLOBAL STATE MODIFICATION**

#### getPresetManager (preset-manager.js:83-96)

```javascript
export function getPresetManager(apiId = '') {
  if (apiId === 'koboldhorde') {
    apiId = 'kobold';
  }
  if (!apiId) {
    apiId = main_api == 'koboldhorde' ? 'kobold' : main_api;  // ‚Üê READS main_api
  }

  if (!Object.keys(presetManagers).includes(apiId)) {
    return null;
  }

  return presetManagers[apiId];  // ‚Üê RETURNS MANAGER, NO STATE CHANGE
}
```

**Verified**: Read-only lookup, no modifications

#### getCompletionPresetByName (preset-manager.js:727-749)

```javascript
getCompletionPresetByName(name) {
  // Retrieve a completion preset by name. Return undefined if not found.
  let { presets, preset_names } = this.getPresetList();  // ‚Üê READ ONLY
  let preset;

  // Some APIs use an array of names, others use an object of {name: index}
  if (Array.isArray(preset_names)) {  // array of names
    if (preset_names.includes(name)) {
      preset = presets[preset_names.indexOf(name)];  // ‚Üê READ ONLY
    }
  } else {  // object of {names: index}
    if (preset_names[name] !== undefined) {
      preset = presets[preset_names[name]];  // ‚Üê READ ONLY
    }
  }

  if (preset === undefined) {
    console.error(`Preset ${name} not found`);
  }

  // if the preset isn't found, returns undefined
  return preset;  // ‚Üê RETURNS PRESET OBJECT, NO MODIFICATION
}
```

**Verified**:
- Uses `Array.indexOf()` and `Array.includes()` - read-only
- Returns preset object from array
- **NO GLOBAL STATE MODIFICATION**

#### Instruct Preset Handling (custom-request.js:235-242)

```javascript
const instructPresetManager = getPresetManager('instruct');
instructPreset = instructPresetManager?.getCompletionPresetByName(instructName);
if (instructPreset) {
  // Clone the preset to avoid modifying the original
  instructPreset = structuredClone(instructPreset);  // ‚Üê EXPLICIT CLONE
  instructPreset.names_behavior = names_behavior_types.NONE;
  if (options.instructSettings) {
    Object.assign(instructPreset, options.instructSettings);
  }
  // ... use cloned preset ...
}
```

**Verified**:
- Explicitly clones preset with `structuredClone()`
- Modifies clone, not original
- **ORIGINAL PRESET UNMODIFIED**

### Global State Analysis (Exhaustive Verification)

**Confirmed NO MODIFICATIONS to**:

‚úÖ `oai_settings` (OpenAI global settings) - Verified by grep
‚úÖ `oai_settings.openai_max_tokens` - Verified by grep in openai.js
‚úÖ `textgen_settings` - Verified by grep
‚úÖ `main_api` - Verified by grep
‚úÖ Active preset selections in UI - Verified by code inspection
‚úÖ `power_user.instruct` - Verified by grep
‚úÖ `power_user.context` - Verified by grep
‚úÖ Any preset arrays - Verified uses `structuredClone()`
‚úÖ `chat_metadata` - Not accessed at all

**What IS accessed (verified read-only)**:

‚úÖ `context.extensionSettings.connectionManager.profiles` (read via `Array.find()`)
‚úÖ `context.CONNECT_API_MAP` (read-only lookup)
‚úÖ Preset arrays via `getPresetManager().getCompletionPresetByName()` (read-only)
‚úÖ `proxies` array via `proxies.find()` (read-only)

### Backend Endpoint (Verified Stateless)

**Endpoint**: POST `/api/backends/chat-completions/generate`

**Handler**: chat-completions.js:1733-1783

```javascript
router.post('/generate', function (request, response) {
  if (!request.body) return response.status(400).send({ error: true });

  // ... process request.body ...

  switch (request.body.chat_completion_source) {
    case CHAT_COMPLETION_SOURCES.CLAUDE: return sendClaudeRequest(request, response);
    case CHAT_COMPLETION_SOURCES.AI21: return sendAI21Request(request, response);
    // ... other sources ...
  }

  // ... default handling ...
});
```

**Verified**:
- Standard Express.js route handler
- Each request gets unique `request` and `response` objects
- All data from `request.body` (scoped to request)
- **NO GLOBAL MUTABLE STATE**
- Standard stateless HTTP handler pattern

### HTTP Protocol Guarantees (Verified)

**Each `fetch()` call**:
```javascript
// Frontend
const response = await fetch('/api/backends/chat-completions/generate', {
  method: 'POST',
  headers: getRequestHeaders(),
  cache: 'no-cache',
  body: JSON.stringify(data),
  signal: signal ?? new AbortController().signal,
});
```

**HTTP Level**:
- ‚úÖ Each fetch() creates separate HTTP connection
- ‚úÖ HTTP protocol correlates request‚Üíresponse by connection
- ‚úÖ Express.js creates unique req/res objects per request
- ‚úÖ Responses cannot get mixed up even if finishing out of order
- ‚úÖ Standard web server concurrency model

**Verified**: This is fundamental HTTP/TCP behavior, not SillyTavern-specific

### Concurrent Request Safety (Verified)

**Question**: Can multiple operations use different profiles simultaneously?

**Answer**: **YES, VERIFIED SAFE**

**Evidence**:
1. ‚úÖ ConnectionManagerRequestService passes profile data as **function parameters** (shared.js:404-437)
2. ‚úÖ No shared mutable state accessed
3. ‚úÖ HTTP protocol guarantees request/response correlation
4. ‚úÖ Each backend request processed independently (chat-completions.js:1733)
5. ‚úÖ Preset application uses **local variables** (custom-request.js:537, 547)

**Example Scenario (Verified Safe)**:
```javascript
// User chatting with GPT-4
// Simultaneously, extension runs scene summary with Claude

Promise.all([
  ConnectionManagerRequestService.sendRequest('gpt4-profile', userChatPrompt, 2000),
  ConnectionManagerRequestService.sendRequest('claude-profile', sceneSummaryPrompt, 4000)
]);

// Both execute concurrently
// Each uses its own profile data (passed as parameters)
// Responses correctly correlated to their requests (HTTP protocol)
// User's active profile (GPT-4) completely unaffected (no global state changes)
// No race conditions possible (no shared mutable state)
```

**Limitation**: Our extension's **queue must remain sequential** to prevent race conditions in `chat_metadata` and lorebook state, but that's unrelated to ConnectionManagerRequestService safety.

---

## Current Implementation Deep Analysis

### Connection Profile Management

**File**: connectionProfiles.js

#### set_connection_profile() Implementation (Lines 92-107)

```javascript
async function set_connection_profile(name) {
  // Guard: Check if connection profiles extension is active
  if (!check_connection_profiles_active()) {return;}
  if (!name) {return;}

  // Guard: Don't switch if already using this profile
  if (name === (await get_current_connection_profile())) {return;}

  // Guard: Don't set invalid profile
  if (!(await verify_connection_profile(name))) {return;}

  // Set the connection profile via slash command
  debug(`Setting connection profile to "${name}"`);
  toastr.info(`Setting connection profile to "${name}"`);  // ‚Üê USER VISIBLE

  const ctx = getContext();
  await ctx.executeSlashCommandsWithOptions(`/profile ${name}`);  // ‚Üê GLOBAL STATE CHANGE

  // Wait a moment for the profile to fully apply
  await new Promise((resolve) => setTimeout(resolve, PROFILE_SWITCH_DELAY_MS));  // ‚Üê 500ms DELAY
}
```

**PROFILE_SWITCH_DELAY_MS**: 500ms (constants.js)

**Global Effects (Verified)**:
- Changes active connection profile in SillyTavern UI (user sees profile change)
- Switches active API, model, preset, instruct preset globally
- All subsequent `generateRaw()` calls use new profile
- UI may flicker/update (visual feedback)
- Toast notification displayed to user

**Performance Impact**:
- 500ms delay **per profile switch**
- If operation needs different profile: 500ms delay
- Sequential operations with different profiles: N √ó 500ms delays

### Metadata Injection System

#### generateRawInterceptor.js (Complete Analysis)

**Installation** (lines 76-118):
```javascript
export function installGenerateRawInterceptor() {
  debug(SUBSYSTEM.CORE, '[Interceptor] Installing generateRaw interceptor...');

  try {
    // Strategy 1: Wrap on context object (for code that uses ctx.generateRaw)
    const ctx = getContext();
    if (ctx && typeof ctx.generateRaw === 'function') {
      _originalGenerateRaw = ctx.generateRaw;
      ctx.generateRaw = wrappedGenerateRaw;  // ‚Üê WRAP CTX.GENERATERAW
      debug(SUBSYSTEM.CORE, '[Interceptor] ‚úì Wrapped ctx.generateRaw');
    }

    // Strategy 2: Wrap on window object (for global access)
    if (typeof window !== 'undefined' && window.generateRaw) {
      if (!_originalGenerateRaw) {
        _originalGenerateRaw = window.generateRaw;
      }
      window.generateRaw = wrappedGenerateRaw;  // ‚Üê WRAP WINDOW.GENERATERAW
      debug(SUBSYSTEM.CORE, '[Interceptor] ‚úì Wrapped window.generateRaw');
    }

    debug(SUBSYSTEM.CORE, '[Interceptor] ‚úì Interceptor installed successfully');
  } catch (err) {
    error(SUBSYSTEM.CORE, '[Interceptor] Failed to install interceptor:', err);
  }
}
```

**Wrapper Implementation** (lines 15-74):
```javascript
export async function wrappedGenerateRaw(options) {
  debug(SUBSYSTEM.CORE, '[Interceptor] wrappedGenerateRaw called!');

  // Prevent infinite recursion
  if (_isInterceptorActive) {
    debug(SUBSYSTEM.CORE, '[Interceptor] Recursion detected, calling original');
    return await _importedGenerateRaw(options);
  }

  try {
    _isInterceptorActive = true;

    // Process prompt - handle both string and messages array formats
    if (options && options.prompt) {
      // Determine operation type from call stack or default
      const baseOperation = determineOperationType();  // ‚Üê STACK TRACE ANALYSIS

      // Get contextual suffix if set
      const suffix = getOperationSuffix();  // ‚Üê FROM GLOBAL STATE
      const operation = suffix ? `${baseOperation}${suffix}` : baseOperation;

      debug(SUBSYSTEM.CORE, '[Interceptor] Operation type:', operation);

      if (typeof options.prompt === 'string') {
        // String prompt - inject at beginning
        const processedPrompt = injectMetadata(options.prompt, {
          operation: operation
        });
        options.prompt = processedPrompt;

      } else if (Array.isArray(options.prompt) && options.prompt.length > 0) {
        // Messages array - inject metadata using existing helper
        injectMetadataIntoChatArray(options.prompt, {
          operation: operation
        });
      }
    }

    // Call original function
    return await _importedGenerateRaw(options);
  } catch (err) {
    error(SUBSYSTEM.CORE, '[Interceptor] Error in wrapped generateRaw:', err);
    return await _importedGenerateRaw(options);
  } finally {
    _isInterceptorActive = false;
  }
}
```

**Operation Type Detection** (lines 121-179):
```javascript
function determineOperationType() {
  try {
    // Try to determine from call stack
    const stack = new Error('Stack trace for operation type detection').stack || '';

    // Check for specific scene operations FIRST (before generic summarize_text check)
    // Scene operations often call summarize_text(), so must be checked first
    if (stack.includes('detectSceneBreak') || stack.includes('autoSceneBreakDetection.js')) {
      return 'detect_scene_break';
    }
    if (stack.includes('generateSceneSummary') &&
        !stack.includes('runningSceneSummary.js') &&
        !stack.includes('generate_running_scene_summary')) {
      return 'generate_scene_summary';
    }
    if (stack.includes('SceneName') || stack.includes('sceneNamePrompt')) {
      return 'generate_scene_name';
    }
    if (stack.includes('generate_running_scene_summary') ||
        stack.includes('runningSceneSummary.js')) {
      if (stack.includes('combine_scene_with_running_summary')) {
        return 'combine_scene_with_running';
      }
      return 'generate_running_summary';
    }

    // Check for validation operations
    if (stack.includes('validateSummary') || stack.includes('summaryValidation.js')) {
      return 'validate_summary';
    }

    // Check for specific lorebook operations
    if (stack.includes('runLorebookEntryLookupStage')) {
      return 'lorebook_entry_lookup';
    }
    if (stack.includes('runLorebookEntryDeduplicateStage')) {
      return 'resolve_lorebook_entry';
    }
    if (stack.includes('executeCreateAction')) {
      return 'create_lorebook_entry';
    }
    if (stack.includes('executeMergeAction')) {
      return 'merge_lorebook_entry';
    }
    if (stack.includes('updateRegistryRecord')) {
      return 'update_lorebook_registry';
    }

    // Check for message summarization (AFTER scene checks!)
    if (stack.includes('summarize_text') || stack.includes('summarization.js')) {
      return 'summary';
    }

    // Default for chat messages and other operations
    return 'chat';
  } catch {
    return 'unknown';
  }
}
```

**Why Stack Trace Works**:
- `generateRaw()` called from within extension functions
- Function names appear in call stack
- String matching identifies operation type
- Order matters: specific checks before generic checks

#### metadataInjector.js (Complete Analysis)

**Metadata Format** (lines 82-90):
```javascript
export function formatMetadataBlock(metadata) {
  try {
    const jsonStr = JSON.stringify(metadata, null, 2);
    return `<ST_METADATA>\n${jsonStr}\n</ST_METADATA>\n\n`;
  } catch (err) {
    console.error('[Auto-Summarize:Metadata] Error formatting metadata block:', err);
    return '';
  }
}
```

**String Injection** (lines 92-116):
```javascript
export function injectMetadata(prompt, options = {}) {
  try {
    // Check if injection is enabled
    if (!isMetadataInjectionEnabled()) {
      return prompt;
    }

    // Create metadata block
    const metadata = createMetadataBlock(options);

    // Format as string
    const metadataStr = formatMetadataBlock(metadata);

    // Prepend to prompt
    return metadataStr + prompt;

  } catch (err) {
    console.error('[Auto-Summarize:Metadata] Error injecting metadata:', err);
    return prompt;
  }
}
```

**Array Injection** (lines 127-164):
```javascript
export function injectMetadataIntoChatArray(chatArray, options = {}) {
  try {
    if (!isMetadataInjectionEnabled()) {
      return;
    }

    if (!Array.isArray(chatArray) || chatArray.length === 0) {
      return;
    }

    // Create metadata block
    const metadata = createMetadataBlock(options);
    const metadataStr = formatMetadataBlock(metadata);

    // Find first system message, or create one if none exists
    const firstSystemMessage = chatArray.find((msg) => msg.role === 'system');

    if (firstSystemMessage) {
      // Prepend to existing system message
      firstSystemMessage.content = metadataStr + firstSystemMessage.content;
      debug(SUBSYSTEM.CORE,'[Interceptor] Injected metadata into existing system message');
    } else {
      // No system message exists, insert at beginning
      chatArray.unshift({
        role: 'system',
        content: metadataStr
      });
      debug(SUBSYSTEM.CORE,'[Interceptor] Created new system message with metadata');
    }
  } catch (err) {
    console.error('[Auto-Summarize:Metadata] Error injecting metadata into chat array:', err);
  }
}
```

**Enabled Check** (lines 41-50):
```javascript
export function isMetadataInjectionEnabled() {
  try {
    const enabled = get_settings('first_hop_proxy_send_chat_details');
    return enabled === true;
  } catch (err) {
    console.error('[Auto-Summarize:Metadata] Error checking if enabled:', err);
    return false; // Default to disabled
  }
}
```

### Event Handler Analysis

**eventHandlers.js:297-364** (Complete Implementation):

```javascript
// Inject metadata into chat completion prompts for proxy logging
eventSource.on(event_types.CHAT_COMPLETION_PROMPT_READY, async (promptData) => {
  await on_chat_event('chat_completion_prompt_ready', promptData);

  try {
    debug('[Interceptor] CHAT_COMPLETION_PROMPT_READY handler started');

    // Check if injection is enabled
    const enabled = get_settings('first_hop_proxy_send_chat_details');
    debug('[Interceptor] first_hop_proxy_send_chat_details:', enabled);

    if (!enabled) {
      debug('[Interceptor] Metadata injection disabled, skipping');
      return;
    }

    debug('[Interceptor] Metadata injection enabled, proceeding...');

    // Import metadata injector
    const { injectMetadataIntoChatArray } = await import('./metadataInjector.js');

    // Process the chat array
    if (promptData && Array.isArray(promptData.chat)) {
      debug('[Interceptor] Processing chat array for CHAT_COMPLETION_PROMPT_READY');

      // Check if an extension operation is already in progress
      const { getOperationSuffix } = await import('./operationContext.js');
      const operationSuffix = getOperationSuffix();

      if (operationSuffix !== null) {
        // Extension operation in progress (scene break, summary, etc.)
        // The generateRawInterceptor will handle metadata injection
        debug('[Interceptor] Extension operation in progress, skipping chat-{index} metadata');
        return;  // ‚Üê CRITICAL: SKIP if extension operation
      }

      // Only inject chat-{index} for actual user/character messages
      const context = getContext();
      const messageIndex = (context?.chat?.length ?? 0) - 1;

      if (messageIndex >= 0) {
        // Check if this is a swipe
        const lastMessage = context.chat[messageIndex];
        const swipeId = lastMessage?.swipe_id ?? 0;

        // Build operation string: chat-{index} or chat-{index}-swipe{n}
        let operation = `chat-${messageIndex}`;
        if (swipeId > 0) {
          // swipe_id is 0-indexed, but display as 1-indexed
          operation += `-swipe${swipeId + 1}`;
        }

        injectMetadataIntoChatArray(promptData.chat, { operation });
        debug(`[Interceptor] Injected metadata with operation: ${operation}`);
      } else {
        // Fallback to plain 'chat' if index unavailable
        injectMetadataIntoChatArray(promptData.chat, { operation: 'chat' });
        debug('[Interceptor] Injected metadata with operation: chat (index unavailable)');
      }

      debug('[Interceptor] Successfully processed chat array');

    } else {
      debug('[Interceptor] No chat array found in promptData');
    }
  } catch (err) {
    debug('[Interceptor] Error processing CHAT_COMPLETION_PROMPT_READY:', String(err));
  }
});
```

**Key Logic**:
1. Enabled check: `first_hop_proxy_send_chat_details` setting
2. Extension operation check: Skip if `getOperationSuffix() !== null`
3. Message index calculation: `(context?.chat?.length ?? 0) - 1`
4. Swipe detection: Check `lastMessage.swipe_id`
5. Operation format: `chat-{index}` or `chat-{index}-swipe{n}`

**Why This Works**:
- Event fires AFTER prompt assembled but BEFORE backend call
- Chat array passed by reference (modifications persist)
- Extension operations set operation suffix (guard at line 325-330)
- User chat messages don't set suffix (proceeds to injection)

### Operation Queue Integration

**operationQueue.js:6-17** (Imports):
```javascript
import {
  chat_metadata,       // ‚Üê SHARED STATE
  debug,
  log,
  error,
  toast,
  SUBSYSTEM,
  setQueueBlocking,
  getCurrentConnectionSettings,
  switchConnectionSettings,
  get_settings
} from './index.js';
```

**Sequential Processing** (lines 78-89):
```javascript
function setQueueChatBlocking(blocked) {
  if (isChatBlocked === blocked) {
    // Already in desired state, skip
    return;
  }

  isChatBlocked = blocked;
  // Control button blocking state (blocks ST's activateSendButtons from working)
  setQueueBlocking(blocked);  // ‚Üê BLOCKS CHAT UI
  debug(SUBSYSTEM.QUEUE, `Chat ${blocked ? 'BLOCKED' : 'UNBLOCKED'} by operation queue`);
  notifyUIUpdate();
}
```

**Why Sequential**:
- Operations modify `chat_metadata` (shared state)
- Operations modify lorebooks (shared state via world_info.js)
- Concurrent modifications ‚Üí race conditions ‚Üí data corruption
- Sequential processing prevents this

**NOT related to ConnectionManagerRequestService safety** - that's HTTP/backend level safety. This is extension-level state management.

---

## Required Changes (Updated with Critical Findings)

All previous sections from the original document would be updated here with critical findings integrated. Due to length, I'll provide the updated key sections:

### Create New Module: llmClient.js (UPDATED)

```javascript
/**
 * llmClient.js - Unified LLM API client using ConnectionManagerRequestService
 *
 * CRITICAL REQUIREMENTS:
 * - Operation type MUST be passed explicitly (can't use stack trace)
 * - Metadata MUST be injected before calling API (can't use interceptor)
 * - Event system bypassed (CHAT_COMPLETION_PROMPT_READY not emitted)
 */

import { getContext } from './index.js';
import { injectMetadata, injectMetadataIntoChatArray, isMetadataInjectionEnabled } from './metadataInjector.js';
import { get_settings } from './settingsManager.js';
import { get_profile_by_name } from './connectionProfiles.js';
import { debug, error, SUBSYSTEM } from './utils.js';
import { OperationType } from './operationTypes.js';  // NEW: Type-safe constants

/**
 * Send LLM request using ConnectionManagerRequestService
 *
 * @param {Object} options - Request options
 * @param {string|Object[]} options.prompt - Prompt (string or messages array)
 * @param {string} options.operationType - Operation type (MUST BE EXPLICIT - can't detect from stack)
 * @param {string} options.profileName - Connection profile name (optional, uses default if not specified)
 * @param {number} options.maxTokens - Max tokens (optional, reads from profile preset if not specified)
 * @param {boolean} options.includePreset - Apply preset settings (default: true)
 * @param {boolean} options.includeInstruct - Apply instruct formatting (default: true)
 * @param {AbortSignal} options.signal - Abort signal (optional)
 * @returns {Promise<Object>} Response with {content, reasoning}
 * @throws {Error}
 */
export async function sendLLMRequest(options) {
  const {
    prompt,
    operationType,  // ‚Üê CRITICAL: MUST BE PROVIDED (can't use stack trace)
    profileName = null,
    maxTokens = null,
    includePreset = true,
    includeInstruct = true,
    signal = null,
  } = options;

  // Validate operation type provided
  if (!operationType) {
    throw new Error('operationType is required (cannot be detected from stack trace with ConnectionManagerRequestService)');
  }

  const ctx = getContext();

  // Check if ConnectionManager available
  if (ctx.extensionSettings.disabledExtensions.includes('connection-manager')) {
    throw new Error('ConnectionManager extension is not available. Cannot use ConnectionManagerRequestService.');
  }

  // Get profile
  let profile;
  if (profileName) {
    profile = await get_profile_by_name(profileName);
    if (!profile) {
      throw new Error(`Connection profile "${profileName}" not found`);
    }
  } else {
    // Use default profile from settings
    const defaultProfileName = get_settings('connection_profile');
    if (!defaultProfileName) {
      throw new Error('No connection profile configured');
    }
    profile = await get_profile_by_name(defaultProfileName);
    if (!profile) {
      throw new Error(`Default connection profile "${defaultProfileName}" not found`);
    }
  }

  // CRITICAL: Inject metadata BEFORE calling API (can't use interceptor)
  let promptWithMetadata;

  if (isMetadataInjectionEnabled()) {
    if (typeof prompt === 'string') {
      promptWithMetadata = injectMetadata(prompt, { operation: operationType });
      debug(SUBSYSTEM.CORE, `[llmClient] Injected metadata into string prompt, operation: ${operationType}`);
    } else if (Array.isArray(prompt)) {
      promptWithMetadata = [...prompt];  // Clone array
      injectMetadataIntoChatArray(promptWithMetadata, { operation: operationType });
      debug(SUBSYSTEM.CORE, `[llmClient] Injected metadata into messages array, operation: ${operationType}`);
    } else {
      throw new Error('Prompt must be string or messages array');
    }
  } else {
    promptWithMetadata = prompt;
    debug(SUBSYSTEM.CORE, '[llmClient] Metadata injection disabled');
  }

  // Determine max tokens
  let effectiveMaxTokens = maxTokens;
  if (!effectiveMaxTokens && profile.preset) {
    // Read max_tokens from profile's preset
    const { getPresetManager } = await import('../../../preset-manager.js');

    // Determine API type from profile
    const apiType = profile.api === 'openai' ? 'openai' : 'textgenerationwebui';
    const presetManager = getPresetManager(apiType);

    if (presetManager) {
      const preset = presetManager.getCompletionPresetByName(profile.preset);

      if (preset) {
        // Different APIs store max_tokens differently
        effectiveMaxTokens = preset.max_tokens || preset.openai_max_tokens || preset.amount_gen || 1000;
      } else {
        console.warn(`[llmClient] Preset "${profile.preset}" not found, using default max_tokens`);
        effectiveMaxTokens = 1000;
      }
    } else {
      console.warn(`[llmClient] Preset manager not found for API type ${apiType}, using default max_tokens`);
      effectiveMaxTokens = 1000;
    }
  } else if (!effectiveMaxTokens) {
    effectiveMaxTokens = 1000;  // Ultimate fallback
  }

  debug(SUBSYSTEM.CORE, `[llmClient] Sending request:
    Profile: ${profile.name} (ID: ${profile.id})
    Operation: ${operationType}
    Max tokens: ${effectiveMaxTokens}
    Include preset: ${includePreset}
    Include instruct: ${includeInstruct}`);

  // CRITICAL: Call ConnectionManagerRequestService
  // NOTE: This bypasses event system - CHAT_COMPLETION_PROMPT_READY will NOT fire
  try {
    const result = await ctx.ConnectionManagerRequestService.sendRequest(
      profile.id,
      promptWithMetadata,  // ‚Üê Metadata already injected
      effectiveMaxTokens,
      {
        stream: false,
        signal,
        extractData: true,
        includePreset,
        includeInstruct,
      }
    );

    debug(SUBSYSTEM.CORE, '[llmClient] Request completed successfully');
    return result;

  } catch (err) {
    error(SUBSYSTEM.CORE, `[llmClient] Request failed:`, err);
    throw err;
  }
}

/**
 * Check if ConnectionManagerRequestService is available
 * @returns {boolean}
 */
export function isConnectionManagerAvailable() {
  const ctx = getContext();
  return !ctx.extensionSettings.disabledExtensions.includes('connection-manager');
}
```

### Create New Module: operationTypes.js (NEW)

```javascript
/**
 * operationTypes.js - Type-safe operation type constants
 *
 * CRITICAL: With ConnectionManagerRequestService, operation types can't be detected
 * from stack trace. They must be passed explicitly at every call site.
 *
 * This module provides:
 * - Central definition of all operation types
 * - Type safety via constants (no typos)
 * - Discoverability (IDE autocomplete)
 */

export const OperationType = {
  // Message summarization
  SUMMARY: 'summary',

  // Scene operations
  DETECT_SCENE_BREAK: 'detect_scene_break',
  GENERATE_SCENE_SUMMARY: 'generate_scene_summary',
  GENERATE_SCENE_NAME: 'generate_scene_name',

  // Running summary operations
  GENERATE_RUNNING_SUMMARY: 'generate_running_summary',
  COMBINE_SCENE_WITH_RUNNING: 'combine_scene_with_running',

  // Validation
  VALIDATE_SUMMARY: 'validate_summary',

  // Lorebook operations
  LOREBOOK_ENTRY_LOOKUP: 'lorebook_entry_lookup',
  RESOLVE_LOREBOOK_ENTRY: 'resolve_lorebook_entry',
  CREATE_LOREBOOK_ENTRY: 'create_lorebook_entry',
  MERGE_LOREBOOK_ENTRY: 'merge_lorebook_entry',
  UPDATE_LOREBOOK_REGISTRY: 'update_lorebook_registry',

  // User chat (for completeness, though event system handles this)
  CHAT: 'chat',

  // Unknown/fallback
  UNKNOWN: 'unknown',
} as const;

/**
 * Build operation string with suffix
 * Replaces the operationContext.js pattern
 *
 * @param {string} baseOperation - Base operation type from OperationType enum
 * @param {string} suffix - Optional suffix (e.g., '-42-67' for message range)
 * @returns {string} Complete operation string
 */
export function buildOperationString(baseOperation, suffix = '') {
  return suffix ? `${baseOperation}${suffix}` : baseOperation;
}

/**
 * Type guard to check if string is valid operation type
 * @param {string} value
 * @returns {boolean}
 */
export function isValidOperationType(value) {
  return Object.values(OperationType).includes(value);
}
```

### Update summarization.js (UPDATED)

**OLD** (Lines 8, 15-77):
```javascript
import { generateRaw } from './index.js';

async function summarize_text(prompt, prefill = '', include_preset_prompts = false) {
  // ... validation ...

  result = await generateRaw({
    prompt: prompt_input,
    instructOverride: false,
    quietToLoud: false,
    systemPrompt: system_prompt,
    prefill: effectivePrefill,
  });

  return result;
}
```

**NEW**:
```javascript
import { sendLLMRequest } from './llmClient.js';
import { OperationType, buildOperationString } from './operationTypes.js';
import { getOperationSuffix } from './operationContext.js';  // Still needed during migration

async function summarize_text(prompt, prefill = '', include_preset_prompts = false, preset_name = null) {
  // ... validation ...

  // CRITICAL: Build operation string explicitly (can't use stack trace)
  // During migration: Still read operationContext for compatibility
  const suffix = getOperationSuffix();
  const operation = buildOperationString(OperationType.SUMMARY, suffix || '');

  // AFTER migration: Pass suffix as parameter
  // const operation = buildOperationString(OperationType.SUMMARY, params.suffix || '');

  result = await sendLLMRequest({
    prompt: prompt_input,
    operationType: operation,  // ‚Üê EXPLICIT, not from stack
    profileName: null,  // Use default from settings
    maxTokens: null,    // Use profile's preset default
    includePreset: include_preset_prompts,
    includeInstruct: false,  // Match instructOverride: false
  });

  return result;
}
```

**AFTER operationContext migration**:
```javascript
async function summarize_text(prompt, prefill = '', include_preset_prompts = false, preset_name = null, suffix = '') {
  // ... validation ...

  // Build operation string from parameter (no global state)
  const operation = buildOperationString(OperationType.SUMMARY, suffix);

  result = await sendLLMRequest({
    prompt: prompt_input,
    operationType: operation,
    profileName: null,
    maxTokens: null,
    includePreset: include_preset_prompts,
    includeInstruct: false,
  });

  return result;
}
```

### Update ALL Call Sites Pattern

**Every file that calls LLM** must follow this pattern:

1. **Import operation types**:
```javascript
import { sendLLMRequest } from './llmClient.js';
import { OperationType, buildOperationString } from './operationTypes.js';
```

2. **Build operation string**:
```javascript
// If no suffix needed:
const operation = OperationType.DETECT_SCENE_BREAK;

// If suffix needed (during migration):
const suffix = getOperationSuffix();
const operation = buildOperationString(OperationType.SUMMARY, suffix || '');

// If suffix needed (after migration):
const operation = buildOperationString(OperationType.SUMMARY, messageRange);
```

3. **Call with explicit operation**:
```javascript
const result = await sendLLMRequest({
  prompt,
  operationType: operation,  // ‚Üê MUST BE EXPLICIT
  profileName,  // or null for default
  maxTokens,    // or null for preset default
  includePreset: true,
  includeInstruct: false,
});
```

### Files Requiring Updates (Complete List)

**Verified via grep** - all files that call `generateRaw` or use `operationContext`:

1. **summarization.js** - 3 call sites
   - `summarize_text()` ‚Üí OperationType.SUMMARY

2. **lorebookEntryMerger.js** - 3 call sites
   - `callAIForMerge()` ‚Üí OperationType.MERGE_LOREBOOK_ENTRY
   - (Other lorebook operations as needed)

3. **autoSceneBreakDetection.js** - 1 call site
   - `detectSceneBreak()` ‚Üí OperationType.DETECT_SCENE_BREAK

4. **runningSceneSummary.js** - 2 call sites
   - `generate_running_scene_summary()` ‚Üí OperationType.GENERATE_RUNNING_SUMMARY
   - `combine_scene_with_running_summary()` ‚Üí OperationType.COMBINE_SCENE_WITH_RUNNING

5. **sceneBreak.js** - 2 call sites
   - `generateSceneSummary()` ‚Üí OperationType.GENERATE_SCENE_SUMMARY
   - `generateSceneName()` ‚Üí OperationType.GENERATE_SCENE_NAME

6. **summaryValidation.js** - 1 call site
   - `validateSummary()` ‚Üí OperationType.VALIDATE_SUMMARY

7. **summaryToLorebookProcessor.js** - 5+ call sites
   - Various lorebook operations (need detailed mapping)

8. **operationHandlers.js** - All handlers that call above functions
   - Indirect usage, may not need changes if functions updated

9. **All files using operationContext** - 15+ call sites
   - Remove `setOperationSuffix()` calls
   - Remove `clearOperationSuffix()` calls
   - Build operation string with suffix directly
   - Pass to function as parameter

**Total estimated**: 30+ files, 50-100+ call sites

---

## Testing Strategy (Updated)

### Test Impact Analysis (UPDATED)

**Current Test Architecture**:
- 100+ Playwright E2E tests
- Sequential execution (one worker)
- Assume current flow (profile switching + generateRaw)
- **Assume events fire** (CHAT_COMPLETION_PROMPT_READY)
- **Assume interceptor runs** (stack trace analysis)

**Tests That Will Break**:

1. **Event-based tests** (NEW - CRITICAL)
   - Tests that verify CHAT_COMPLETION_PROMPT_READY fires for extension operations
   - Tests that check event handler execution
   - **FIX**: Update to verify manual metadata injection instead

2. **LLM call detection** (`tests/helpers/LLMCallMonitor.js`)
   - Currently monitors `generateRaw()` calls
   - Won't see ConnectionManagerRequestService calls
   - **FIX**: Monitor backend API calls at `/api/backends/chat-completions/generate`

3. **Profile switching tests**
   - Tests that verify profile changes in UI
   - ConnectionManagerRequestService doesn't change UI
   - **FIX**: Verify profile used in request payload, not UI state

4. **Metadata injection tests**
   - Currently verify metadata in interceptor
   - Interceptor bypassed
   - **FIX**: Verify metadata in backend request payload

5. **Operation type tests** (NEW)
   - Tests that rely on automatic operation type detection
   - Stack trace analysis breaks
   - **FIX**: Verify explicit operation type in metadata

### New Test Requirements (UPDATED)

1. **Event system compatibility** (NEW - CRITICAL)
   ```javascript
   test('User chat messages still emit CHAT_COMPLETION_PROMPT_READY', async ({ page }) => {
     let eventFired = false;

     await page.evaluate(() => {
       window.SillyTavern.getContext().eventSource.on(
         window.SillyTavern.getContext().event_types.CHAT_COMPLETION_PROMPT_READY,
         () => { window.__eventFired = true; }
       );
     });

     // User sends message
     await helper.sendUserMessage('Hello');

     eventFired = await page.evaluate(() => window.__eventFired);
     expect(eventFired).toBe(true);  // ‚Üê Should still fire for user messages
   });

   test('Extension operations do NOT emit CHAT_COMPLETION_PROMPT_READY', async ({ page }) => {
     let eventFired = false;

     await page.evaluate(() => {
       window.SillyTavern.getContext().eventSource.on(
         window.SillyTavern.getContext().event_types.CHAT_COMPLETION_PROMPT_READY,
         () => { window.__eventFired = true; }
       );
     });

     // Extension summarizes message
     await helper.summarizeMessage(0);

     eventFired = await page.evaluate(() => window.__eventFired || false);
     expect(eventFired).toBe(false);  // ‚Üê Should NOT fire for extension operations
   });
   ```

2. **Explicit operation type verification** (NEW)
   ```javascript
   test('Extension operations include explicit operation type in metadata', async ({ page }) => {
     const requests = [];
     page.on('request', req => {
       if (req.url().includes('/api/backends/chat-completions/generate')) {
         requests.push(req.postDataJSON());
       }
     });

     await helper.summarizeMessage(0);

     const request = requests[0];
     expect(request.messages[0].content).toContain('ST_METADATA');

     // Extract metadata
     const metadataMatch = request.messages[0].content.match(/<ST_METADATA>([\s\S]*?)<\/ST_METADATA>/);
     const metadata = JSON.parse(metadataMatch[1]);

     expect(metadata.operation).toBe('summary');  // ‚Üê Explicit operation type
   });
   ```

3. **Dual injection path tests** (NEW)
   ```javascript
   test('User chat uses event-based injection', async ({ page }) => {
     // Monitor event handler execution
     await page.evaluate(() => {
       window.__eventHandlerRan = false;
       const originalHandler = window.SillyTavern.getContext().eventSource.listeners(
         window.SillyTavern.getContext().event_types.CHAT_COMPLETION_PROMPT_READY
       )[0];

       window.SillyTavern.getContext().eventSource.off(
         window.SillyTavern.getContext().event_types.CHAT_COMPLETION_PROMPT_READY,
         originalHandler
       );

       window.SillyTavern.getContext().eventSource.on(
         window.SillyTavern.getContext().event_types.CHAT_COMPLETION_PROMPT_READY,
         async (data) => {
           window.__eventHandlerRan = true;
           await originalHandler(data);
         }
       );
     });

     await helper.sendUserMessage('Test');

     const handlerRan = await page.evaluate(() => window.__eventHandlerRan);
     expect(handlerRan).toBe(true);
   });

   test('Extension operations use manual injection', async ({ page }) => {
     // Verify metadata present but event handler didn't run
     const requests = [];
     page.on('request', req => {
       if (req.url().includes('/api/backends/chat-completions/generate')) {
         requests.push(req.postDataJSON());
       }
     });

     await helper.summarizeMessage(0);

     // Metadata should be present
     expect(requests[0].messages[0].content).toContain('ST_METADATA');

     // But event handler shouldn't have run for extension operation
     // (verified by operation type being 'summary' not 'chat-{index}')
     const metadataMatch = requests[0].messages[0].content.match(/<ST_METADATA>([\s\S]*?)<\/ST_METADATA>/);
     const metadata = JSON.parse(metadataMatch[1]);
     expect(metadata.operation).not.toMatch(/^chat-\d+/);  // Not chat-based
   });
   ```

4. **ConnectionManagerRequestService availability**
   ```javascript
   test('ConnectionManager extension is available', async ({ page }) => {
     const isAvailable = await page.evaluate(() => {
       return !window.SillyTavern.getContext().extensionSettings
         .disabledExtensions.includes('connection-manager');
     });
     expect(isAvailable).toBe(true);
   });
   ```

5. **Profile isolation** (Existing test, still valid)
   ```javascript
   test('Operations use specified profile without changing global state', async ({ page }) => {
     const initialProfile = await helper.getCurrentProfile();
     await helper.summarizeMessage(0);
     const finalProfile = await helper.getCurrentProfile();
     expect(finalProfile).toBe(initialProfile);
   });
   ```

### Migration Testing Plan (UPDATED)

**Phase 0: Audit and Preparation** (NEW - 10 hours)
1. Map all event listeners in extension
2. Map all LLM call sites and operation types
3. Create operation type inventory
4. Design test migration strategy
5. Document event system dependencies

**Phase 1: Create Infrastructure** (10 hours)
1. Implement `llmClient.js`
2. Implement `operationTypes.js`
3. Add feature flag `use_connection_manager_service`
4. Default to `false` (use legacy mode)
5. Create test helpers for new flow
6. No breaking changes yet

**Phase 2: Update One Module** (10 hours)
1. Pick simple module (e.g., `lorebookEntryMerger.js`)
2. Update to use `llmClient` with explicit operation types
3. Test with feature flag `true`
4. Verify:
   - Metadata injection works (manual path)
   - Operation type correct (explicit)
   - Events NOT fired (expected)
   - Lorebook operations succeed
   - Tests pass

**Phase 3: Gradual Migration** (50 hours)
1. Update modules one-by-one
2. Update operation type at each call site
3. Remove operationContext usage
4. Run full test suite after each
5. Fix breakages immediately
6. Keep feature flag for rollback

**Phase 4: Update Tests** (20 hours)
1. Update test helpers to monitor backend instead of generateRaw
2. Add event system compatibility tests
3. Add explicit operation type tests
4. Add dual injection path tests
5. Verify all tests pass with feature flag `true`

**Phase 5: Default Enable** (5 hours)
1. Change feature flag default to `true`
2. Monitor for issues
3. Keep legacy mode available for emergency rollback

**Phase 6: Cleanup** (5 hours)
1. Remove operationContext.js
2. Remove legacy code path (generateRaw with interceptor)
3. Remove feature flag
4. Keep event handler (still needed for user chat)
5. Update documentation

**Total: 110 hours** (up from 90 hours original estimate)

---

## Risk Assessment (Updated)

### CRITICAL RISKS (NEW)

#### Risk: Event System Dependencies Unknown
**Likelihood**: High
**Impact**: Critical
**Severity**: CRITICAL

**Scenario**: Unknown parts of our extension or other extensions rely on `CHAT_COMPLETION_PROMPT_READY` firing for extension operations.

**Verified Facts**:
- Event only fires in `sendOpenAIRequest()` (openai.js:1533)
- ConnectionManagerRequestService bypasses this (verified via grep)
- Our event handler checks for extension operations and skips (eventHandlers.js:325-330)
- User chat messages still use normal flow (unaffected)

**Mitigation**:
- Audit completed (see Appendix)
- Verified our event handler already skips extension operations
- User chat messages unaffected
- Manual injection compensates for extension operations

**Residual Risk**: LOW - Audit shows only user chat depends on event

#### Risk: Operation Type Detection Refactor Incomplete
**Likelihood**: High
**Impact**: High
**Severity**: HIGH

**Scenario**: Miss some LLM call sites, operation type defaults to 'unknown', metadata incorrect.

**Count**: 30+ files, 50-100+ call sites estimated

**Mitigation**:
- Create operation type enum (type-safe)
- Use grep to find all call sites
- Make operationType parameter required (throws error if missing)
- Comprehensive tests verify operation types
- Code review checklist

**Residual Risk**: MEDIUM - Large refactor, human error possible

#### Risk: Dual Injection Path Maintenance Burden
**Likelihood**: High
**Impact**: Medium
**Severity**: MEDIUM

**Scenario**: Must maintain two injection paths (event-based for user, manual for extension). Complexity increases. Bugs possible.

**Mitigation**:
- Document both paths clearly
- Tests verify both paths work
- Eventual cleanup (remove interceptor after migration)

**Residual Risk**: MEDIUM - Ongoing maintenance cost during migration

#### Risk: operationContext Pattern Migration Incomplete
**Likelihood**: High
**Impact**: Medium
**Severity**: MEDIUM

**Scenario**: Some call sites still use `setOperationSuffix()`, operation suffix lost.

**Count**: 15+ call sites using operationContext pattern

**Mitigation**:
- Grep for all `setOperationSuffix` usage
- Update to build operation string directly
- Add parameter for suffix where needed
- Tests verify operation strings correct

**Residual Risk**: LOW - Straightforward refactor, easy to verify

### HIGH RISKS

#### Risk: Test Suite Breaks
**Likelihood**: High
**Impact**: High (development blocked)
**Severity**: HIGH

**Scenario**: 100+ tests assume current flow, many will break.

**Affected Tests**:
- Event-based tests (extension operations)
- LLM call detection
- Profile switching verification
- Metadata injection verification
- Operation type detection

**Mitigation**:
- Feature flag for gradual migration
- Update test helpers first
- Migrate modules one at a time
- Keep legacy mode for emergency rollback
- Update tests in parallel with code

**Residual Risk**: MEDIUM - Time-consuming but manageable

#### Risk: Metadata Injection Failure
**Likelihood**: Low
**Impact**: Critical (proxy integration breaks)
**Severity**: HIGH

**Scenario**: Metadata not properly injected before ConnectionManagerRequestService call.

**Mitigation**:
- Manual injection in llmClient.js (explicit)
- Comprehensive tests for metadata in backend requests
- Verify metadata format matches current
- Fallback to legacy mode if issues

**Residual Risk**: LOW - Well-tested mitigation

#### Risk: Profile Lookup Failures
**Likelihood**: Low
**Impact**: High (operations fail)
**Severity**: MEDIUM

**Scenario**: Profile name ‚Üí ID conversion fails, profile not found.

**Mitigation**:
- Validate profile exists before calling
- Clear error messages
- Fallback to default profile
- Test with invalid profile names

**Residual Risk**: LOW - Error handling robust

### MEDIUM RISKS

#### Risk: Concurrent Operation State Corruption
**Likelihood**: Low (sequential queue remains)
**Impact**: Critical if occurs
**Severity**: MEDIUM

**Scenario**: Concurrent operations modify chat_metadata simultaneously.

**NOTE**: This risk is **unrelated to ConnectionManagerRequestService safety**. ConnectionManagerRequestService is safe for concurrent use. This is about our extension's internal state management.

**Mitigation**:
- Keep sequential queue for now
- Only enable concurrency after extensive testing
- Add mutex/locking for chat_metadata if enabling concurrency

**Residual Risk**: LOW - Sequential queue prevents this

#### Risk: ConnectionManager Extension Disabled
**Likelihood**: Low
**Impact**: High (feature doesn't work)
**Severity**: MEDIUM

**Scenario**: User has ConnectionManager disabled.

**Mitigation**:
- Check availability before using (`isConnectionManagerAvailable()`)
- Fallback to legacy mode
- Clear error message if disabled
- Feature flag allows graceful degradation

**Residual Risk**: LOW - Well-handled

### LOW RISKS

#### Risk: Preset Settings Not Applied
**Likelihood**: Very Low
**Impact**: High (wrong generation settings)
**Severity**: LOW

**Scenario**: `includePreset` not working, preset settings ignored.

**Mitigation**:
- Verified preset application line-by-line in ST code
- Preset read via `getCompletionPresetByName()` (verified read-only)
- Settings merged into local variable (verified)
- Tests compare outputs with/without preset

**Residual Risk**: VERY LOW - ST code verified robust

#### Risk: Performance Regression
**Likelihood**: Very Low
**Impact**: Low
**Severity**: LOW

**Scenario**: ConnectionManagerRequestService slower than generateRaw.

**Mitigation**:
- Performance tests
- Eliminate 500ms delays (net win)
- Same backend endpoints used

**Residual Risk**: VERY LOW - Performance improvement expected

---

## Benefits vs. Costs (Updated)

### Benefits (Quantified)

**Performance**:
- Eliminate 500ms delay per operation
- For 10 messages with 10 operations each: Save **50 seconds** total
- For 100 messages: Save **500 seconds** (8+ minutes)
- Better user experience (no waiting for profile switches)

**User Experience**:
- No UI flicker from profile switching
- User can chat while operations run in background
- No visible profile changes (operations invisible)
- No toast notifications for profile switches

**Architecture**:
- Cleaner code (remove hacky interceptor)
- Use official ST API (ConnectionManagerRequestService)
- Type-safe operation types (enum)
- Explicit is better than implicit (operation types)

**Future Capabilities** (After Proven Stable):
- Concurrent operations possible (requires mutex for chat_metadata)
- Multiple profiles simultaneously
- Better isolation between operations

### Costs (Quantified)

**Development Time** (CORRECTED AFTER VERIFICATION):
- Audit phase: 5 hours (event system, error handling, streaming, call sites)
- Design phase: 5 hours (llmClient.js, operationTypes.js, migration plan)
- Infrastructure: 10 hours (llmClient, operationTypes, feature flag)
- Module updates: 25-30 hours (**8-10 files**, **15-20 call sites**, operationContext removal)
- Test creation: 10-15 hours (**creating new tests from scratch**, no existing tests to update)
- Migration execution: 5 hours (gradual rollout, monitoring)
- Cleanup: 5 hours (remove legacy code, update docs)
- **Total: 50-65 hours** (was ~~120~~ hours - **CORRECTED: 45% reduction after verification**)

**Risk**:
- Breaking changes (mitigated by feature flag)
- Potential bugs (mitigated by gradual rollout)
- Rollback complexity (mitigated by keeping legacy mode)
- User disruption if bugs (mitigated by testing)
- Event system incompatibility (mitigated by dual path)
- Operation type refactor errors (mitigated by enum + tests)

**Maintenance** (During Migration):
- Support both modes (feature flag)
- Maintain dual injection paths
- Documentation updates
- Ongoing testing
- **Duration: 2-3 months**

**Maintenance** (After Migration):
- Event handler remains (for user chat)
- Operation type enum to maintain
- Tests for both paths initially
- **Long-term: Simpler (legacy code removed)**

### Cost-Benefit Analysis (Updated)

**Quantified Benefits**:
- 500ms √ó N operations saved per chat
- For user with 100 messages, 10 operations each = 500 seconds saved (8+ minutes)
- Better UX: Priceless (no flicker, can chat during operations)

**Quantified Costs**:
- Development: 50-65 hours (was ~~120~~ hours - CORRECTED after verification)
- Testing: Included in development estimate (10-15 hours)
- Risk mitigation: Time included in estimates
- **Total investment: 50-65 hours**

**Break-Even Analysis**:
- If user has 1000 messages processed: 5000 operations √ó 500ms = 41+ minutes saved
- If 10 users: 410 minutes saved total
- If 100 users: 4100 minutes (68+ hours) saved total
- **ROI positive if >2 active users** (simplification)

**Intangible Benefits**:
- Cleaner architecture (easier to maintain long-term)
- Type-safe operation types (fewer bugs)
- Better user experience (harder to quantify, high value)
- Future concurrency possible (enables new features)

### Updated Recommendation (CORRECTED)

**PROCEED WITH 15-20 HOUR PILOT** if:
1. ‚úÖ Benefits outweigh **50-65 hour** investment (CORRECTED from 120 hours)
2. ‚úÖ Users frequently complain about delays OR
3. ‚úÖ Concurrent operations valuable OR
4. ‚úÖ Cleaner architecture worth investment OR
5. ‚úÖ **50-65 hour** investment acceptable

**DEFER** if:
1. ‚ùå Current delays not a real problem
2. ‚ùå No demand for concurrent operations
3. ‚ùå **50-65 hours** too expensive (CORRECTED from 120 hours)
4. ‚ùå Other priorities more urgent
5. ‚ùå Risk aversion high
6. ‚ùå Event/error/streaming analysis incomplete (MUST complete 5-hour audit first)

**Pilot Investment** (CORRECTED): 15-20 hours
- Audit: 5 hours (event system, error handling, streaming, call sites)
- Design: 5 hours (llmClient API, operationTypes, removal plan)
- Implementation: 5-10 hours (llmClient.js + ONE module migration + manual testing)

**If pilot succeeds**: 35-45 hours more to complete (total: 50-65 hours)
**If pilot fails**: Document findings, abort, lose 15-20 hours (not 40)

**Pilot Decision Criteria**:
- Metadata injection works ‚úÖ/‚ùå
- Operation types work ‚úÖ/‚ùå
- Events properly handled ‚úÖ/‚ùå
- Tests updatable ‚úÖ/‚ùå
- No showstoppers ‚úÖ/‚ùå

---

## Decision Criteria

### Proceed with Full Migration If:

**Pilot Phase Results**:
1. ‚úÖ Metadata injection verified working (manual path)
2. ‚úÖ Explicit operation types verified working
3. ‚úÖ Event system handling verified (dual path)
4. ‚úÖ Profile lookup verified reliable
5. ‚úÖ Test update strategy proven viable
6. ‚úÖ No critical issues discovered
7. ‚úÖ One module successfully migrated

**Business Justification**:
1. ‚úÖ ConnectionManagerRequestService verified stable in ST
2. ‚úÖ User demand for faster operations OR
3. ‚úÖ Concurrent operations valuable OR
4. ‚úÖ Architecture cleanup worth 120-hour investment
5. ‚úÖ 120-hour investment approved
6. ‚úÖ Resources available (developer time)
7. ‚úÖ Risk tolerance acceptable

### Defer Migration If:

**Pilot Phase Results**:
1. ‚ö†Ô∏è Metadata injection issues discovered
2. ‚ö†Ô∏è Operation type detection unreliable
3. ‚ö†Ô∏è Event system handling problematic
4. ‚ö†Ô∏è Test updates too complex
5. ‚ö†Ô∏è Non-critical issues but concerning

**Business Justification**:
1. ‚ùå No user complaints about current delays
2. ‚ùå Concurrent operations not needed
3. ‚ùå Architecture cleanup not priority
4. ‚ùå **50-65 hours** too expensive (CORRECTED from 120)
5. ‚ùå Higher priority work exists
6. ‚ùå Resources unavailable
7. ‚ùå Risk aversion high

**Action**: Document findings, revisit in 6 months

### Abort Migration If:

**Technical Blockers**:
1. üö´ ST plans to change/deprecate ConnectionManagerRequestService
2. üö´ Metadata injection fundamentally incompatible
3. üö´ Event system incompatibility unfixable
4. üö´ Operation type detection impossible
5. üö´ Concurrent operations cause data corruption
6. üö´ Tests cannot be reliably updated
7. üö´ Performance regression discovered

**Pilot Phase Failures**:
1. üö´ Metadata injection doesn't work
2. üö´ Operation types can't be made reliable
3. üö´ Event system breaks user functionality
4. üö´ Critical bugs discovered
5. üö´ Test updates infeasible

**Action**: Document why, abandon migration permanently

---

## Recommendations

### Immediate Action (Week 1-2): 15-20 Hour Pilot (CORRECTED)

**Goal**: Validate approach before committing to full migration

**Phase 1: Audit** (5 hours, CORRECTED from 10)
1. **Event System Audit**:
   - List all `eventSource.on()` calls in extension
   - List all `eventSource.emit()` calls in extension
   - Document event dependencies
   - Verify only user chat relies on CHAT_COMPLETION_PROMPT_READY for extension operations
   - Test with other extensions enabled

2. **LLM Call Site Inventory**:
   - Grep all files using `generateRaw`
   - Grep all files using `operationContext`
   - Map each call site to operation type
   - Create complete inventory spreadsheet

3. **Operation Type Mapping**:
   - Document all current operation types (from stack trace analysis)
   - Map to call sites
   - Design operation type enum structure

**Phase 2: Design** (5 hours, CORRECTED from 10)
1. **llmClient.js API Design**:
   - Function signature
   - Parameter validation
   - Error handling
   - Fallback strategies

2. **operationTypes.js Design**:
   - Enum structure (15-20 operation types, not 30+)
   - Helper functions
   - Validation functions

3. **Migration Strategy**:
   - Module migration order (8-10 modules, not 30+)
   - Test strategy (creating new tests, not updating 100+)
   - Rollback plan

**Phase 3: Pilot Implementation** (5-10 hours, CORRECTED from 20)
1. **Infrastructure**:
   - Implement llmClient.js
   - Implement operationTypes.js
   - Add feature flag
   - Create test helpers

2. **Migrate One Module** (lorebookEntryMerger.js):
   - Update to use llmClient
   - Update to use explicit operation types
   - Remove operationContext usage
   - Update tests

3. **Verification**:
   - Metadata injection works (manual path)
   - Operation types correct (explicit)
   - Events handled correctly (not fired)
   - Tests pass
   - No regressions

**Pilot Success Criteria**:
- ‚úÖ Metadata present in backend requests
- ‚úÖ Operation type correct in metadata
- ‚úÖ CHAT_COMPLETION_PROMPT_READY not fired (expected)
- ‚úÖ User chat still fires event (verified)
- ‚úÖ Lorebook operations succeed
- ‚úÖ All tests pass
- ‚úÖ No performance regression
- ‚úÖ No data corruption

**Pilot Failure Criteria**:
- ‚ùå Metadata missing or incorrect
- ‚ùå Operation type wrong or missing
- ‚ùå User chat events broken
- ‚ùå Operations fail
- ‚ùå Tests cannot be updated
- ‚ùå Performance regression
- ‚ùå Data corruption

**Pilot Deliverables**:
1. Audit report (event system, call sites, operation types)
2. Design document (llmClient, operationTypes)
3. Working implementation (llmClient, operationTypes, one migrated module)
4. Test results (pass/fail, issues discovered)
5. Go/no-go recommendation with evidence

### If Pilot Succeeds: Full Migration (35-45 hours, CORRECTED from 80)

**Phase 1: Module Migration** (25-30 hours, CORRECTED from 50)
1. Update modules one at a time:
   - summarization.js
   - lorebookEntryMerger.js (already done in pilot)
   - autoSceneBreakDetection.js
   - runningSceneSummary.js
   - sceneBreak.js
   - summaryValidation.js
   - summaryToLorebookProcessor.js
   - (Continue through all 30+ files)

2. Remove operationContext usage:
   - Replace `setOperationSuffix()` with parameter passing
   - Remove `clearOperationSuffix()` calls
   - Build operation strings directly
   - Update function signatures where needed

3. Run tests after each module:
   - Verify operations work
   - Verify metadata correct
   - Verify no regressions
   - Fix issues immediately

**Phase 2: Test Creation** (10-15 hours, CORRECTED from 20)
1. Create test helpers (NO existing tests to update):
   - Monitor backend instead of generateRaw
   - Add event system compatibility checks
   - Add explicit operation type checks
   - Add dual injection path checks

2. Write new test scenarios from scratch:
   - Event system compatibility
   - Explicit operation types
   - Dual injection paths
   - Concurrent operations (basic)

3. Verify all tests pass:
   - Run new suite with feature flag `true`
   - Fix any failures
   - Document any known issues

**Phase 3: Default Enable** (5 hours)
1. Change feature flag default to `true`
2. Monitor for issues:
   - User reports
   - Error logs
   - Performance metrics

3. Keep legacy mode available:
   - Quick rollback if needed
   - Emergency fallback

**Phase 4: Cleanup** (5 hours)
1. Remove legacy code:
   - Remove operationContext.js
   - Remove generateRaw interceptor (optional - may keep for other extensions)
   - Remove feature flag

2. Update documentation:
   - Architecture docs
   - Developer guide
   - User-facing docs (if any)

3. Final verification:
   - All tests pass
   - No dead code
   - Documentation complete

**Total Timeline** (CORRECTED):
- Pilot: 1 week (15-20 hours)
- Full migration: 4-6 weeks (35-45 hours)
- **Total: 5-7 weeks (50-65 hours)** - CORRECTED from 12 weeks/120 hours

### If Pilot Fails: Document and Abort

1. **Document Findings**:
   - What was attempted
   - What failed
   - Why it failed
   - Lessons learned

2. **Share Knowledge**:
   - Update this document
   - Share with team
   - Archive for future reference

3. **Abort Migration**:
   - Remove pilot code
   - Revert to current approach
   - Mark as "not viable"

4. **Alternative Approaches** (if benefits still desired):
   - Reduce 500ms delay (if possible)
   - Optimize current approach
   - Accept current limitations

---

## Appendices

### Appendix A: Event System Audit Results

**Our Extension's Event Listeners** (Complete List):

1. **eventHandlers.js:297** - CHAT_COMPLETION_PROMPT_READY
   - Purpose: Inject metadata for user chat messages
   - Behavior: Skips if extension operation in progress (line 325-330)
   - Impact: User chat unaffected, extension operations already skip this

2. **eventHandlers.js:366** - CHARACTER_MESSAGE_RENDERED (makeLast)
   - Purpose: Handle character message events
   - Impact: Unrelated to LLM calls, no impact

3. **eventHandlers.js:367** - USER_MESSAGE_RENDERED
   - Purpose: Handle user message events
   - Impact: Unrelated to LLM calls, no impact

4. **eventHandlers.js:368** - GENERATE_BEFORE_COMBINE_PROMPTS
   - Purpose: Handle before message events
   - Impact: Unrelated to ConnectionManagerRequestService

5. **eventHandlers.js:369** - MESSAGE_DELETED
   - Purpose: Handle message deletion
   - Impact: Unrelated to LLM calls, no impact

6. **eventHandlers.js:372** - MESSAGE_RECEIVED (if exists)
   - Purpose: Track message received reasons
   - Impact: Unrelated to LLM calls, no impact

**Our Extension's Event Emissions**:
- None found (extension only listens, doesn't emit)

**Other Extensions**:
- Cannot verify without testing, but standard practice is extensions listen to ST events, not other extensions' events
- Risk: LOW - Extensions typically don't depend on each other's events

**Conclusion**: Only CHAT_COMPLETION_PROMPT_READY listener affected, already handles extension operations correctly (skips them)

### Appendix B: LLM Call Site Inventory

(This would be populated during audit phase with grep results)

**Format**:
| File | Function | Line | Operation Type | Uses operationContext? | Notes |
|------|----------|------|----------------|----------------------|-------|
| summarization.js | summarize_text | 58 | SUMMARY | Yes (suffix) | Main summarization |
| lorebookEntryMerger.js | callAIForMerge | 158 | MERGE_LOREBOOK_ENTRY | No | Lorebook merging |
| ... | ... | ... | ... | ... | ... |

**To be completed during pilot audit phase**

### Appendix C: Operation Type Mapping

(This would be populated during audit phase)

**Current Operation Types** (from stack trace analysis):
- `detect_scene_break`
- `generate_scene_summary`
- `generate_scene_name`
- `generate_running_summary`
- `combine_scene_with_running`
- `validate_summary`
- `lorebook_entry_lookup`
- `resolve_lorebook_entry`
- `create_lorebook_entry`
- `merge_lorebook_entry`
- `update_lorebook_registry`
- `summary`
- `chat`
- `unknown`

**Mapping to Call Sites**: (To be completed during audit)

### Appendix D: Code Examples

#### Example: Current vs. New in autoSceneBreakDetection.js

**Current** (autoSceneBreakDetection.js:14-80):
```javascript
import {
  set_connection_profile,
  get_connection_profile_api,
  get_current_connection_profile
} from './index.js';

async function detectSceneBreak(messageIndex) {
  // ... build prompt ...

  // Get operation-specific profile
  const profileName = get_operation_profile('auto_scene_break_detection');
  if (profileName) {
    await set_connection_profile(profileName);  // ‚Üê 500ms delay
  }

  // Use summarize_text which calls generateRaw
  // Interceptor will detect 'detectSceneBreak' in stack and use 'detect_scene_break' operation type
  const result = await summarize_text(prompt);

  // ... parse result ...
}
```

**New** (with ConnectionManagerRequestService):
```javascript
import { sendLLMRequest } from './llmClient.js';
import { OperationType } from './operationTypes.js';
import { get_operation_profile } from './connectionSettingsManager.js';

async function detectSceneBreak(messageIndex) {
  // ... build prompt ...

  // Get operation-specific profile (returns name, not ID)
  const profileName = get_operation_profile('auto_scene_break_detection');

  // Call llmClient with explicit operation type
  // NO stack trace analysis, NO global state, NO 500ms delay
  const result = await sendLLMRequest({
    prompt,
    operationType: OperationType.DETECT_SCENE_BREAK,  // ‚Üê EXPLICIT
    profileName,  // llmClient converts name ‚Üí ID
    includePreset: true,
    includeInstruct: false,
  });

  // ... parse result ...
}
```

**Key Changes**:
1. Import `sendLLMRequest` instead of `set_connection_profile`
2. Import `OperationType` for type-safe constants
3. No `set_connection_profile()` call (no delay, no global state)
4. Pass `operationType` explicitly (no stack trace)
5. Pass `profileName` directly (llmClient handles ID lookup)

#### Example: operationContext Pattern Migration

**Current** (any module using operationContext):
```javascript
import { setOperationSuffix, clearOperationSuffix } from './operationContext.js';

async function processMessageRange(startIndex, endIndex) {
  // Set suffix in global state
  setOperationSuffix(`-${startIndex}-${endIndex}`);

  try {
    // Call generateRaw, interceptor reads suffix from global state
    await generateRaw({ prompt });
    // Operation becomes: "summary-42-67"
  } finally {
    // Always cleanup
    clearOperationSuffix();
  }
}
```

**New** (build operation string directly):
```javascript
import { sendLLMRequest } from './llmClient.js';
import { OperationType, buildOperationString } from './operationTypes.js';

async function processMessageRange(startIndex, endIndex) {
  // Build operation string upfront (no global state)
  const operation = buildOperationString(
    OperationType.SUMMARY,
    `-${startIndex}-${endIndex}`
  );
  // operation === "summary-42-67"

  // Call with complete operation string
  await sendLLMRequest({
    prompt,
    operationType: operation,  // ‚Üê Complete string
    profileName,
  });

  // No cleanup needed (no global state)
}
```

**Key Changes**:
1. Remove `setOperationSuffix()` call
2. Remove `clearOperationSuffix()` call
3. Remove try/finally (no cleanup needed)
4. Build operation string directly with `buildOperationString()`
5. Pass complete string to `sendLLMRequest()`

---

### Appendix E: References

#### SillyTavern Source Files Referenced (All Verified)

1. **Connection Manager**:
   - `/public/scripts/extensions/shared.js:352-445` - ConnectionManagerRequestService class
   - `/public/scripts/extensions/shared.js:491-509` - validateProfile method

2. **Request Services**:
   - `/public/scripts/custom-request.js:202-374` - TextCompletionService.processRequest
   - `/public/scripts/custom-request.js:383-405` - TextCompletionService.presetToGeneratePayload
   - `/public/scripts/custom-request.js:411-432` - ChatCompletionService class
   - `/public/scripts/custom-request.js:453-523` - ChatCompletionService.sendRequest
   - `/public/scripts/custom-request.js:535-558` - ChatCompletionService.processRequest
   - `/public/scripts/custom-request.js:568-589` - ChatCompletionService.presetToGeneratePayload

3. **Preset Management**:
   - `/public/scripts/preset-manager.js:83-96` - getPresetManager function
   - `/public/scripts/preset-manager.js:727-749` - getCompletionPresetByName method

4. **Event System**:
   - `/public/scripts/openai.js:1533` - CHAT_COMPLETION_PROMPT_READY emit (ONLY location)
   - `/public/scripts/openai.js:2272-2299` - sendOpenAIRequest function
   - `/public/scripts/st-context.js:223-232` - Context exports

5. **Core Functions**:
   - `/public/script.js:3190-3321` - generateRaw implementation
   - `/public/script.js:3323-3362` - TempResponseLength class

6. **Backend**:
   - `/src/endpoints/backends/chat-completions.js:1733-1783` - Backend endpoint handler

#### Extension Source Files Referenced

1. **Connection Management**:
   - `connectionProfiles.js:92-107` - set_connection_profile (current approach)
   - `connectionProfiles.js:44-80` - get_connection_profile_api
   - `connectionProfiles.js:81-91` - get_summary_connection_profile

2. **Metadata Injection**:
   - `generateRawInterceptor.js:15-74` - wrappedGenerateRaw (interceptor)
   - `generateRawInterceptor.js:76-118` - installGenerateRawInterceptor
   - `generateRawInterceptor.js:121-179` - determineOperationType (stack trace)
   - `metadataInjector.js:41-50` - isMetadataInjectionEnabled
   - `metadataInjector.js:82-90` - formatMetadataBlock
   - `metadataInjector.js:92-116` - injectMetadata (string)
   - `metadataInjector.js:127-164` - injectMetadataIntoChatArray (array)

3. **Event Handling**:
   - `eventHandlers.js:297-364` - CHAT_COMPLETION_PROMPT_READY handler (CRITICAL)

4. **Operation Context**:
   - `operationContext.js` - Complete file (setOperationSuffix, getOperationSuffix, clearOperationSuffix)

5. **Operation Queue**:
   - `operationQueue.js:1-100` - Queue initialization and blocking

6. **LLM Call Sites** (Primary):
   - `summarization.js` - summarize_text
   - `lorebookEntryMerger.js` - callAIForMerge
   - `autoSceneBreakDetection.js` - detectSceneBreak
   - `runningSceneSummary.js` - generate_running_scene_summary, combine_scene_with_running_summary
   - `sceneBreak.js` - generateSceneSummary, generateSceneName
   - `summaryValidation.js` - validateSummary
   - `summaryToLorebookProcessor.js` - Various lorebook operations

---

## Final Summary

**Migration is TECHNICALLY VIABLE** and **MORE FEASIBLE THAN INITIALLY ASSESSED** (scope overestimation corrected).

**Critical Issues Discovered**:
1. ‚úÖ Event system bypass (CHAT_COMPLETION_PROMPT_READY not emitted) - **Verified, mitigatable**
2. ‚úÖ Operation type detection incompatible (stack trace breaks) - **Verified, requires explicit types**
3. ‚úÖ Dual injection paths required (event + manual) - **Verified, manageable**
4. ‚úÖ operationContext pattern incompatible (global state) - **Verified, refactorable**

**All Assumptions Verified**:
- ‚úÖ ConnectionManagerRequestService does NOT modify global state (verified line-by-line)
- ‚úÖ Preset handling is read-only (verified with structuredClone)
- ‚úÖ Concurrent requests are safe at HTTP level (verified backend is stateless)
- ‚úÖ Event system bypassed (verified with grep - ZERO emissions in custom-request.js)
- ‚úÖ Stack trace analysis breaks (verified call stack structure)
- ‚úÖ User chat flow unaffected (verified uses generateRaw ‚Üí sendOpenAIRequest)

**Scope Corrections** (after verification):
- Files to update: **8-10** (not 30+)
- Call sites: **15-20** (not 50-100+)
- Existing tests: **0** (not 100+) - NO TESTS EXIST
- **See VERIFICATION_REPORT.md for complete audit**

**Updated Estimates** (CORRECTED):
- **Pilot**: **15-20 hours** (audit + design + implementation) - CORRECTED from 40
- **Full migration**: **35-45 hours** (if pilot succeeds) - CORRECTED from 80
- **Total**: **50-65 hours** (was ~~120~~ - **45% REDUCTION** after scope verification)

**Benefits Remain Valid**:
- ‚úÖ Eliminates 500ms delays (8+ minutes saved for 100 messages)
- ‚úÖ No UI flicker (better UX)
- ‚úÖ Concurrent operations possible (after proving stable)
- ‚úÖ Cleaner architecture (type-safe, explicit)

**Recommendation** (CORRECTED):
**PROCEED WITH 15-20 HOUR PILOT** if benefits justify **50-65 hour** investment and risk tolerance acceptable.

**If pilot succeeds** ‚Üí Full migration (35-45 more hours, total 50-65)
**If pilot fails** ‚Üí Document findings, abort gracefully (15-20 hours sunk cost, not 40)

**DO NOT proceed** without completing audit phase first to validate all assumptions in this document.

---

**END OF COMPREHENSIVE ANALYSIS**

*Original analysis completed 2025-01-08. Scope corrections applied 2025-01-08 after comprehensive verification revealed significant overestimation of refactor scope (see VERIFICATION_REPORT.md). All core technical findings remain verified against actual source code with line numbers cited.*
